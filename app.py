import streamlit as st
import sqlite3
import pandas as pd
import pdfplumber
from huggingface_hub import hf_hub_download
import google.generativeai as genai
import os
from io import StringIO
from pathlib import Path

# --- Configura√ß√£o Inicial e Verifica√ß√£o de Secrets ---

# Configura√ß√£o de secrets (Streamlit Cloud)
HF_TOKEN = st.secrets.get("HF_TOKEN", "")
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")

# Verifica se os secrets est√£o configurados
if not HF_TOKEN or not GEMINI_API_KEY:
    st.error("ERRO: Configure **HF_TOKEN** e **GEMINI_API_KEY** nos secrets do Streamlit Cloud (Settings -> Secrets).")
    st.stop()

# Configurar Gemini
try:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash')
except Exception as e:
    st.error(f"ERRO ao configurar o Gemini: {e}")
    st.stop()

# --- Fun√ß√µes de Carregamento de Recursos (Otimizadas com Cache) ---

# Baixar DB do HuggingFace (cache em /tmp). Esta fun√ß√£o ser√° chamada dentro do st.status.
@st.cache_resource
def load_db_cached(hf_token_value):
    db_path = hf_hub_download(
        repo_id="TiagoPianezzola/BI",
        filename="almg_local.db",
        token=hf_token_value, # Usamos o token carregado para garantir que a fun√ß√£o use o secret
        local_dir="/tmp"
    )
    return db_path

# Wrapper para for√ßar o download com feedback e evitar o timeout inicial.
def load_db_with_status():
    st.info("Aguardando cache do banco de dados...")
    
    # Usamos o st.status para contornar o timeout de startup
    with st.status("Preparando recursos: **Baixando DB de 100MB** (pode levar alguns minutos na primeira vez)...", expanded=True) as status:
        try:
            status.update(label="Iniciando download do banco de dados do Hugging Face...", state="running")
            # Chama a fun√ß√£o cachead para fazer o download
            db_path = load_db_cached(HF_TOKEN)
            status.update(label="Banco de Dados ALMG carregado com sucesso!", state="complete")
            st.success("Base de dados pronta.")
            return db_path
        except Exception as e:
            status.update(label=f"ERRO CR√çTICO ao baixar o DB: {e}", state="error")
            st.error(f"ERRO CR√çTICO no download do DB. Verifique seu **HF_TOKEN** ou a conex√£o. Detalhes: {e}")
            st.stop()

# Ler schema do TXT
@st.cache_data
def load_schema_txt():
    file_name = "armazem_estruturado.txt"
    if not Path(file_name).exists():
        raise FileNotFoundError(f"ERRO: Arquivo **{file_name}** n√£o encontrado no reposit√≥rio.")
    
    with open(file_name, "r", encoding="utf-8") as f:
        return f.read()

# Extrair texto do PDF
@st.cache_data
def load_pdf_text():
    file_name = "armazem.pdf"
    if not Path(file_name).exists():
        raise FileNotFoundError(f"ERRO: Arquivo **{file_name}** n√£o encontrado no reposit√≥rio.")

    pdf_text = ""
    try:
        with pdfplumber.open(file_name) as pdf:
            for page in pdf.pages:
                pdf_text += page.extract_text() or ""
        return pdf_text
    except Exception as e:
        raise Exception(f"ERRO ao processar o PDF. Detalhes: {e}")


# --- Fun√ß√µes de L√≥gica do Chatbot (Sem Altera√ß√µes) ---

def generate_sql(question, schema_txt, pdf_text):
    prompt = f"""
    Voc√™ √© um especialista em SQL para o dataset ALMG. Gere UMA query SQL v√°lida e simples para responder √† pergunta em linguagem natural.
    
    Schema das tabelas e colunas (use EXATAMENTE essas):
    {schema_txt}
    
    Contexto detalhado das tabelas/colunas (use para escolher o que representa melhor o conceito na pergunta):
    {pdf_text}
    
    Pergunta do usu√°rio: {question}
    
    Regras:
    - Use apenas SELECT (nada de INSERT/UPDATE/DELETE/DROP para seguran√ßa).
    - Limite a 100 resultados: adicione LIMIT 100.
    - Seja preciso: associe conceitos da pergunta √†s colunas certas baseando no contexto.
    - Retorne APENAS a query SQL, sem explica√ß√µes.
    """
    response = model.generate_content(prompt)
    sql = response.text.strip().strip("```sql").strip("```").strip()
    
    # Valida√ß√£o b√°sica de seguran√ßa
    forbidden = ["DROP", "DELETE", "UPDATE", "INSERT", "ALTER"]
    if any(word in sql.upper() for word in forbidden):
        raise ValueError("Query SQL inv√°lida ou insegura detectada.")
    return sql

def execute_and_format(sql, db_path, question):
    conn = sqlite3.connect(db_path)
    try:
        df = pd.read_sql_query(sql, conn)
        if df.empty:
            return "Nenhum resultado encontrado para essa pergunta."
        
        csv_buffer = StringIO()
        df.to_csv(csv_buffer, index=False)
        csv_data = csv_buffer.getvalue()
        
        prompt_format = f"""
        Formate esta resposta SQL de forma natural e √∫til em portugu√™s, como um relat√≥rio curto.
        Pergunta original: {question}
        Query executada: {sql}
        Resultados (CSV): {csv_data}
        
        Responda em PT-BR, com:
        - Resumo chave (1-2 frases).
        - Tabela formatada (descreva se necess√°rio).
        - Insights breves se aplic√°vel.
        Mantenha conciso.
        """
        response = model.generate_content(prompt_format)
        formatted = response.text
        
        # Mostrar tabela raw tamb√©m
        st.dataframe(df, use_container_width=True)
        return formatted
    finally:
        conn.close()

# --- Interface Streamlit Principal ---

st.title("ü§ñ Assistente BI ALMG - Pergunte em Linguagem Natural")

# Carregar recursos cr√≠ticos. AGORA COM FEEDBACK VISUAL.
try:
    # 1. Carrega DB com feedback de status para contornar o timeout
    db_path = load_db_with_status()
    
    # 2. Carrega Schema e PDF. Se falhar, o erro √© mais claro.
    with st.spinner("Carregando Schema e PDF de Contexto..."):
        schema_txt = load_schema_txt()
        pdf_text = load_pdf_text()
    
except (FileNotFoundError, Exception) as e:
    # Exibe o erro se os arquivos locais estiverem faltando ou se o PDF for inv√°lido
    st.error(f"ERRO no carregamento de arquivos locais: {str(e)}. Verifique se **armazem_estruturado.txt** e **armazem.pdf** est√£o no seu reposit√≥rio.")
    st.stop()


# Chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Sidebar com exemplos (Sem Altera√ß√µes)
with st.sidebar:
    st.header("Exemplos de Perguntas")
    examples = [
        "Quantos deputados h√° na ALMG?",
        "Qual o gasto total em 2023?",
        "Liste as comiss√µes ativas."
    ]
    for ex in examples:
        if st.button(ex, key=ex):
            st.session_state.messages.append({"role": "user", "content": ex})
            st.rerun()

# Exibir hist√≥rico (Sem Altera√ß√µes)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usu√°rio (Sem Altera√ß√µes)
if prompt := st.chat_input("Digite sua pergunta sobre os dados ALMG:"):
    # Adicionar √† history
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("Gerando query SQL..."):
            try:
                sql = generate_sql(prompt, schema_txt, pdf_text)
                st.info(f"**Query SQL gerada:**\n```{sql}```")
                
                with st.spinner("Executando e formatando..."):
                    response = execute_and_format(sql, db_path, prompt)
                    st.markdown(response)
                
                # Salvar na history
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"Erro: {str(e)}. Verifique a pergunta ou logs.")

# Footer
st.markdown("---")
st.caption("App constru√≠do com Streamlit + Gemini + HuggingFace. Dataset privado ALMG.")
